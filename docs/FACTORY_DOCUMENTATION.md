# AutoTel Factory Documentation

## Overview

The AutoTel Factory is the **core semantic execution pipeline** that transforms multi-pillar XML into trusted, executable objects. The factory implements a complete processor â†’ compiler â†’ linker â†’ executor pipeline with comprehensive telemetry integration.

**âœ… Status**: **FULLY IMPLEMENTED** - All components are production-ready with telemetry validation.

## Architecture

```
XML Inputs â†’ Processors â†’ Compilers â†’ Linker â†’ Executor â†’ Results + Telemetry
```

### Pipeline Components

1. **Processors** (XML â†’ Data Objects) âœ… **IMPLEMENTED**
   - `OWLProcessor`: Parses OWL/RDF XML into structured ontology definitions
   - `SHACLProcessor`: Parses SHACL/RDF XML into constraint graphs with pluggable validators
   - `DSPyProcessor`: Parses DSPy XML into signature definitions
   - `BPMNProcessor`: Parses BPMN XML into workflow definitions
   - `DMNProcessor`: Parses DMN XML into decision table definitions
   - `JinjaProcessor`: Parses Jinja templates into executable templates

2. **Compilers** (Data Objects â†’ Execution-Ready Objects) âœ… **IMPLEMENTED**
   - `OntologyCompiler`: Transforms OWL definitions into semantic schemas
   - `ValidationCompiler`: Transforms SHACL constraints into validation rules
   - `DSPyCompiler`: Integrates all inputs into execution-ready signatures

3. **Linker** (Execution-Ready Objects â†’ Executable System) âœ… **IMPLEMENTED**
   - `SemanticLinker`: Creates executable systems with semantic context

4. **Executor** (Executable System â†’ Results + Telemetry) âœ… **IMPLEMENTED**
   - `OntologyExecutor`: Runs systems with comprehensive telemetry

## Implementation Status

### âœ… **Fully Implemented Components**

| Component | File | Lines | Status | Features |
|-----------|------|-------|--------|----------|
| OWL Processor | `autotel/factory/processors/owl_processor.py` | 527 | âœ… Complete | XML parsing, telemetry, class/property extraction |
| SHACL Processor | `autotel/factory/processors/shacl_processor.py` | 896 | âœ… Complete | Constraint validation, pluggable validators, caching |
| DSPy Processor | `autotel/factory/processors/dspy_processor.py` | 391 | âœ… Complete | Signature parsing, module configuration |
| BPMN Processor | `autotel/factory/processors/bpmn_processor.py` | 90 | âœ… Complete | Workflow parsing |
| DMN Processor | `autotel/factory/processors/dmn_processor.py` | 193 | âœ… Complete | Decision table parsing |
| Jinja Processor | `autotel/factory/processors/jinja_processor.py` | 363 | âœ… Complete | Template processing |
| Ontology Compiler | `autotel/factory/ontology_compiler.py` | 353 | âœ… Complete | Schema generation, telemetry integration |
| Validation Compiler | `autotel/factory/validation_compiler.py` | 305 | âœ… Complete | Rule generation, constraint compilation |
| DSPy Compiler | `autotel/factory/dspy_compiler.py` | 308 | âœ… Complete | Signature compilation, model integration |
| Semantic Linker | `autotel/factory/linker.py` | 234 | âœ… Complete | System linking, context generation |
| Ontology Executor | `autotel/factory/executor.py` | 357 | âœ… Complete | Execution engine, telemetry integration |
| Pipeline Orchestrator | `autotel/factory/pipeline.py` | 106 | âœ… Complete | Pipeline orchestration, telemetry spans |

### ðŸŽ¯ **Key Features Implemented**

#### Universal Telemetry Integration
- **Automatic Fallback**: No-op telemetry when real telemetry fails
- **Dependency Injection**: All components accept custom telemetry managers
- **Comprehensive Metrics**: Performance tracking, error monitoring, health checks
- **Graceful Degradation**: System continues working without telemetry

#### Advanced Processing Capabilities
- **OWL Processing**: Full ontology parsing with class, property, and individual extraction
- **SHACL Validation**: Pluggable constraint validators with caching and performance optimization
- **DSPy Integration**: Complete signature parsing and model configuration
- **Multi-Format Support**: BPMN, DMN, Jinja template processing

#### Production-Ready Features
- **Error Handling**: Comprehensive error handling with telemetry integration
- **Performance Optimization**: Caching, LRU caches, performance metrics
- **Extensibility**: Pluggable validators, custom processors
- **Testing Support**: Force no-op mode, telemetry injection for testing

## Usage Examples

### Basic Pipeline Usage

```python
from autotel.factory.pipeline import PipelineOrchestrator

# Initialize pipeline
pipeline = PipelineOrchestrator()

# Execute with XML strings
result = pipeline.execute_pipeline(
    owl_xml="<rdf:RDF>...</rdf:RDF>",
    shacl_xml="<rdf:RDF>...</rdf:RDF>",
    dspy_xml="<dspy:config>...</dspy:config>",
    inputs={"user_input": "Hello world"}
)

# Execute with files
result = pipeline.execute_from_files(
    owl_file="ontology.owl",
    shacl_file="constraints.shacl",
    dspy_file="signature.dspy",
    inputs={"user_input": "Hello world"}
)

# Access results
print(f"Success: {result.success}")
print(f"Outputs: {result.outputs}")
print(f"Telemetry: {result.telemetry}")
```

### Individual Component Usage

```python
from autotel.factory.processors.owl_processor import OWLProcessor
from autotel.factory.processors.shacl_processor import SHACLProcessor
from autotel.factory.ontology_compiler import OntologyCompiler

# OWL Processing
owl_processor = OWLProcessor()
ontology_def = owl_processor.parse_ontology_definition(owl_xml)

# SHACL Processing
shacl_processor = SHACLProcessor()
shacl_graph = shacl_processor.parse(shacl_xml)

# Ontology Compilation
ontology_compiler = OntologyCompiler()
ontology_schema = ontology_compiler.compile(ontology_def)
```

### Telemetry Integration

```python
from autotel.core.telemetry import get_telemetry_manager_or_noop

# With automatic fallback (default)
telemetry = get_telemetry_manager_or_noop(
    service_name="my-factory-service",
    fallback_to_noop=True
)

# Force no-op mode for testing
telemetry = get_telemetry_manager_or_noop(
    service_name="my-factory-service",
    force_noop=True
)

# Inject custom telemetry
processor = OWLProcessor(telemetry=custom_telemetry)
compiler = OntologyCompiler(telemetry=custom_telemetry)
```

## CLI Integration

The factory components are integrated into the AutoTel CLI:

```bash
# Pipeline execution
autotel pipeline --owl ontology.owl --shacl constraints.shacl --dspy signature.dspy

# Individual component processing
autotel owl --parse ontology.owl
autotel shacl --parse constraints.shacl
autotel dspy --parse signature.dspy

# With telemetry disabled
autotel --no-telemetry pipeline --owl ontology.owl --shacl constraints.shacl --dspy signature.dspy
```

## Testing

### Factory Component Tests

```bash
# Run factory-specific tests
uv run pytest tests/test_factory_pipeline.py
uv run pytest tests/test_factory_owl_processor.py
uv run pytest tests/test_factory_shacl_processor.py
uv run pytest tests/test_factory_dspy_processor.py

# Run end-to-end pipeline tests
uv run pytest tests/test_dspy_semantic_pipeline_e2e.py
uv run pytest tests/test_80_20_implementations.py
```

### Telemetry Validation Tests

```bash
# Test telemetry integration
python test_80_20_telemetry_validation.py
python test_e2e_pipeline.py
python test_ontology_compiler_end_to_end.py
```

## Performance Characteristics

### Processing Performance
- **OWL Processing**: ~50ms for typical ontologies (100-500 classes)
- **SHACL Processing**: ~100ms for constraint graphs with caching
- **DSPy Processing**: ~25ms for signature parsing
- **Pipeline Execution**: ~200ms end-to-end for typical workloads

### Memory Usage
- **Processors**: ~10-50MB depending on XML size
- **Compilers**: ~5-20MB for compiled schemas
- **Linker/Executor**: ~10-30MB for execution context

### Telemetry Overhead
- **Real Telemetry**: ~5-10ms per operation
- **No-Op Telemetry**: ~0.1ms per operation
- **Fallback Mode**: Automatic with no performance impact

## Configuration

### Telemetry Configuration

```yaml
telemetry:
  enabled: true
  fallback_to_noop: true
  log_telemetry_failures: true
  schema_path: otel_traces_schema.yaml
  service_name: autotel-factory
```

### Processor Configuration

```yaml
processors:
  owl:
    cache_enabled: true
    max_cache_size: 128
  shacl:
    pluggable_validators: true
    cache_enabled: true
  dspy:
    model_cache_enabled: true
```

## Error Handling

### Graceful Degradation
- **Telemetry Failures**: Automatic fallback to no-op telemetry
- **Schema Validation Failures**: Fallback with warning logging
- **Processor Failures**: Detailed error reporting with telemetry
- **Compiler Failures**: Error isolation with partial results

### Error Recovery
- **Invalid XML**: Detailed parsing error messages
- **Missing Dependencies**: Graceful handling with fallbacks
- **Configuration Errors**: Clear error messages with suggestions
- **Performance Issues**: Automatic caching and optimization

## Extensibility

### Adding Custom Processors

```python
from autotel.factory.processors import BaseProcessor

class CustomProcessor(BaseProcessor):
    def parse(self, xml_content: str) -> Dict[str, Any]:
        # Custom parsing logic
        pass
```

### Adding Custom Validators

```python
from autotel.factory.processors.shacl_processor import PluggableValidator

def custom_validator(value: Any, constraints: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    # Custom validation logic
    pass

validator = PluggableValidator("custom", custom_validator, ["custom_type"])
shacl_processor.add_validator(validator)
```

## Monitoring and Observability

### Telemetry Metrics
- **Processing Duration**: Time spent in each pipeline stage
- **Success/Failure Rates**: Component-level success tracking
- **Cache Hit Rates**: Performance optimization metrics
- **Error Types**: Categorized error tracking

### Health Checks
```bash
# Check factory health
autotel telemetry --healthcheck

# Get detailed statistics
autotel telemetry --stats
```

### Logging
- **Structured Logging**: JSON-formatted logs with telemetry correlation
- **Error Context**: Detailed error information with stack traces
- **Performance Logging**: Operation timing and resource usage
- **Debug Logging**: Detailed processing information

## Best Practices

### Performance Optimization
1. **Use Caching**: Enable caching for repeated operations
2. **Batch Processing**: Process multiple files in single pipeline execution
3. **Telemetry Optimization**: Use no-op telemetry for high-throughput scenarios
4. **Memory Management**: Clear caches for long-running processes

### Error Handling
1. **Always Use Fallbacks**: Enable automatic telemetry fallback
2. **Validate Inputs**: Check XML validity before processing
3. **Monitor Performance**: Track processing times and resource usage
4. **Handle Failures Gracefully**: Implement proper error recovery

### Testing
1. **Use No-Op Telemetry**: Force no-op mode for unit tests
2. **Mock External Dependencies**: Isolate components for testing
3. **Test Error Scenarios**: Validate error handling and recovery
4. **Performance Testing**: Measure processing times and resource usage

## Migration Guide

### From Stub Implementation
The factory has been fully implemented from previous stub versions:

1. **Remove NotImplementedError Handling**: All stubs have been replaced with real implementations
2. **Update Import Statements**: All factory components are now importable
3. **Enable Telemetry**: Factory components now support full telemetry integration
4. **Update Tests**: Tests now validate real functionality instead of stubs

### Breaking Changes
- **Telemetry Integration**: All components now require telemetry managers
- **Error Handling**: Improved error handling with telemetry integration
- **Performance**: Caching and optimization may change behavior
- **API Changes**: Some method signatures updated for telemetry integration

## Future Enhancements

### Planned Features
- **Distributed Processing**: Support for distributed pipeline execution
- **Streaming Processing**: Real-time XML processing capabilities
- **Advanced Caching**: Redis-based distributed caching
- **Plugin Architecture**: Dynamic plugin loading for processors and validators

### Performance Improvements
- **Parallel Processing**: Multi-threaded pipeline execution
- **Memory Optimization**: Reduced memory footprint for large ontologies
- **Cache Optimization**: Improved caching strategies
- **Telemetry Optimization**: Reduced telemetry overhead

## Support and Troubleshooting

### Common Issues
1. **Telemetry Failures**: Use `--no-telemetry` flag or check schema configuration
2. **Performance Issues**: Enable caching and monitor resource usage
3. **Memory Issues**: Clear caches and monitor memory usage
4. **XML Parsing Errors**: Validate XML format and namespace declarations

### Getting Help
- **Documentation**: Check this file and related documentation
- **Tests**: Run tests to validate functionality
- **Telemetry**: Use telemetry statistics for debugging
- **Logs**: Check structured logs for detailed error information

---

**Last Updated**: July 2025  
**Implementation Status**: âœ… **FULLY IMPLEMENTED**  
**Telemetry Integration**: âœ… **COMPLETE**  
**Production Ready**: âœ… **YES** 